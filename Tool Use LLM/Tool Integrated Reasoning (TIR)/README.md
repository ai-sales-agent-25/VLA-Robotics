Below are nine recent (2023-2025) academic works that **explicitly explore “tool-integrated reasoning” (TIR)** or very closely related ideas such as code-interpreter calls, external-tool agents, or reinforcement-learning frameworks for autonomous tool use—the same family of techniques highlighted in Section 3 of the AIMO-2 “Winning Solution” paper.&#x20;

| Year     | Paper (authors, venue/ID)                                                                                                                    | Why it matters for TIR                                                                                                                                                                                            |
| -------- | -------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **2025** | **ToRL: Scaling Tool-Integrated RL** – Li, Zou & Liu (arXiv 2503.23383)                                                                      | Treats tool use as an RL problem: the LLM learns, via exploration, when and how to call external calculators or code interpreters, showing substantial accuracy gains on math & reasoning tasks. ([arxiv.org][1]) |
| **2025** | **Agentic Reasoning: Reasoning LLMs with Tools for Deep Research** – Wu, Zhu & Liu (arXiv 2502.04644)                                        | Introduces a multi-tool “agentic” loop (web search + code exec + structured memory) that dynamically selects tools during multi-step reasoning. ([arxiv.org][2])                                                  |
| **2025** | **LIMO: Less is More for Reasoning** – Ye et al. (arXiv 2502.03387)                                                                          | Shows that a small amount of carefully filtered TIR supervision lets an instruct model retain strong tool-calling ability while requiring far less data than prior work. ([arxiv.org][3])                         |
| **2025** | **Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via RL** – Dong & colleagues (arXiv 2505.16410)                                      | Pushes TIR further by letting an LLM learn to orchestrate *multiple* external tools (six in total) through a two-stage RL routine. ([arxiv.org][4])                                                               |
| **2024** | **Efficient Tool Use with Chain-of-Abstraction Reasoning** – Gao et al. (arXiv 2401.17464 / COLING 2025)                                     | Decomposes problems into abstract reasoning “skeletons” first, then concretises them with targeted tool calls—leading to more transferable TIR policies. ([arxiv.org][5])                                         |
| **2024** | **MARIO: MAth Reasoning with code Interpreter Output** – Liao et al. (arXiv 2401.08190)                                                      | Provides a dataset & pipeline where each solution interleaves natural-language steps with Python blocks, making it a ready-made TIR benchmark. ([arxiv.org][6])                                                   |
| **2024** | **InfinityMATH: A Scalable Instruction-Tuning Dataset in Programmatic Mathematical Reasoning** – Zhang et al. (arXiv 2408.07089 / CIKM 2024) | Supplies 100 K+ problems whose solutions are written as executable programs, explicitly encouraging LLMs to “think-then-code.” ([arxiv.org][7])                                                                   |
| **2024** | **Qwen2.5-Math Technical Report** – Yang et al. (arXiv 2409.12122)                                                                           | Describes open-weight math-expert models that natively support both CoT and TIR modes, detailing training tricks for stable tool invocation. ([arxiv.org][8])                                                     |
| **2024** | **Building Math Agents with Multi-Turn Iterative Preference Learning** – Xiong et al. (arXiv 2409.02392)                                     | Incorporates code-interpreter feedback into a preference-learning loop, yielding agents that refine tool-rich reasoning over multiple turns. ([arxiv.org][9])                                                     |

These papers collectively cover new **datasets**, **training frameworks**, and **agent architectures** for TIR. They should provide plenty of fresh perspectives—and citations—beyond the AIMO-2 work you’ve been reading. Happy exploring!

[1]: https://arxiv.org/abs/2503.23383?utm_source=chatgpt.com "[2503.23383] ToRL: Scaling Tool-Integrated RL - arXiv"
[2]: https://arxiv.org/abs/2502.04644?utm_source=chatgpt.com "Agentic Reasoning: Reasoning LLMs with Tools for the Deep ... - arXiv"
[3]: https://arxiv.org/abs/2502.03387?utm_source=chatgpt.com "[2502.03387] LIMO: Less is More for Reasoning - arXiv"
[4]: https://arxiv.org/abs/2505.16410?utm_source=chatgpt.com "Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via ... - arXiv"
[5]: https://arxiv.org/abs/2401.17464?utm_source=chatgpt.com "[2401.17464] Efficient Tool Use with Chain-of-Abstraction Reasoning"
[6]: https://arxiv.org/abs/2401.08190?utm_source=chatgpt.com "[2401.08190] MARIO: MAth Reasoning with code Interpreter Output"
[7]: https://arxiv.org/abs/2408.07089?utm_source=chatgpt.com "InfinityMATH: A Scalable Instruction Tuning Dataset in Programmatic ..."
[8]: https://arxiv.org/abs/2409.12122?utm_source=chatgpt.com "Qwen2.5-Math Technical Report: Toward Mathematical Expert ..."
[9]: https://arxiv.org/abs/2409.02392?utm_source=chatgpt.com "Building Math Agents with Multi-Turn Iterative Preference Learning"
