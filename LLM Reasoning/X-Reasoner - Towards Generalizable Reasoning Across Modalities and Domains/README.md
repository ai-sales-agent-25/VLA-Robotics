https://arxiv.org/abs/2505.03981

**X-REASONER: Towards Generalizable Reasoning Across Modalities and Domains**

**1. Summary and Rating**

This paper investigates the fundamental question of whether reasoning capabilities can be generalized across different modalities (e.g., text to vision-language) and domains (e.g., general to medical) through post-training. The authors find affirmatively that general-domain text-based post-training can indeed instill strong, generalizable reasoning. They introduce X-REASONER, a 7B vision-language model (VLM) post-trained *solely* on general-domain text data. The training employs a two-stage recipe: an initial supervised fine-tuning (SFT) phase using distilled long chain-of-thoughts (CoTs) to learn reasoning patterns, followed by reinforcement learning with verifiable rewards (RLVR) on mathematical textual questions to improve accuracy and generalization.

Experiments demonstrate that X-REASONER successfully transfers its text-learned reasoning capabilities to multimodal and out-of-domain (medical) benchmarks, outperforming existing state-of-the-art models of similar scale that were trained with in-domain and multimodal data. The paper further shows that X-REASONER's performance in specialized domains like medicine can be enhanced by continued post-training on domain-specific text-only data, leading to X-REASONER-MED, which sets new SOTA on several medical benchmarks. The core contributions include the empirical study demonstrating this generalizability, the introduction of the X-REASONER model and its effective text-only post-training recipe, and its successful domain-specific extension (X-REASONER-MED).

**Rating: 9/10**

For a PhD-level audience, this paper presents a significant and somewhat counter-intuitive finding: that complex reasoning, including multimodal reasoning, can be substantially developed through text-only fine-tuning. This has important implications for VLM development, potentially simplifying training by leveraging abundant and verifiable text data. The methodological approach, while combining known techniques (SFT with CoT, RLVR), is applied effectively to demonstrate this core hypothesis. The experimental validation across various general, multimodal, and specialized medical benchmarks appears rigorous, including ablations for "endless thinking" and text-solvable examples to support the claims of true multimodal generalization. The results, showing SOTA performance against models trained with richer (multimodal/in-domain) data, are compelling. The work addresses a pertinent research question in a clear and well-structured manner. While the study is constrained by model scale (7B) and backbone choice (Qwen-VL series), these are acknowledged limitations. The potential impact of its findings on future research into efficient and effective VLM training is substantial.

**2. Main Ideas Discussed**

The main ideas discussed in this paper are:

1.  **Generalizability of Reasoning from Text-Only Training:** The central thesis and key finding is that reasoning capabilities, when properly instilled through general-domain text-based post-training, can effectively generalize not only across different text-based tasks and domains but also to different input modalities (i.e., from text-only training to vision-language tasks) and specialized domains (e.g., medicine). This suggests that the core structures of reasoning are universal enough to be learned from text and transferred.
2.  **An Effective Two-Stage Post-Training Recipe for Generalizable Reasoning:** The paper proposes and validates a specific two-stage post-training strategy for VLMs that relies entirely on general-domain text. This involves:
    *   **Stage 1: Supervised Fine-Tuning (SFT) with distilled long Chain-of-Thoughts (CoTs)** to teach the model explicit, structured reasoning patterns like self-reflection and verification.
    *   **Stage 2: Reinforcement Learning with Verifiable Rewards (RLVR) using mathematical textual questions** to further refine these reasoning capabilities, improve accuracy, and enhance generalization, using mathematics as an "anchor domain."
3.  **Domain Specialization via Continued Domain-Specific Text-Only Training:** While general-domain text training provides a strong foundation for broad reasoning, the paper demonstrates that performance in specialized domains (like medicine) can be significantly further improved by an additional phase of post-training using *text-only* data specific to that domain. This is exemplified by X-REASONER-MED.

**3. 10 Most Important Citations**

1.  Bai et al. 2025. Qwen2.5-VL Technical Report. This paper introduces the Qwen2.5-VL-7B-Instruct model, which serves as the foundational instruction-tuned vision-language model upon which X-REASONER is built and fine-tuned. URL: http://arxiv.org/abs/2502.13923
2.  OpenThoughts Team. 2025a. Open Thoughts. The OpenThoughts-114k dataset, comprising curated reasoning traces on math, coding, and science, is used for the crucial first step (general-domain long-CoT SFT) of the X-REASONER training recipe. URL: https://open-thoughts.ai
3.  Hu et al. 2025. Open-reasoner-zero: An open source approach to scaling up reinforcement learning on the base model. The Orz-math-57k dataset, a collection of mathematical textual questions, is used for the reinforcement learning (RLVR) stage of X-REASONER's training. URL: https://arxiv.org/abs/2503.24290
4.  Shao et al. 2024. DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models. The paper X-REASONER cites this work in the context of using Group Relative Policy Optimization (GRPO) as its reinforcement learning algorithm. URL: http://arxiv.org/abs/2402.03300
5.  DeepSeek-AI et al. 2025. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. This work is significant as the OpenThoughts dataset (used in X-REASONER's SFT stage) was distilled from DeepSeek-R1, and it also explores incentivizing reasoning via RL. URL: http://arxiv.org/abs/2501.12948
6.  Yue et al. 2024a. Mmmu: A massive multi-discipline multi-modal understanding and reasoning benchmark for expert agi. MMMU is a key and challenging multimodal benchmark used extensively in the paper to evaluate X-REASONER's cross-modality generalization capabilities. (No URL provided in the paper's reference list for this specific entry)
7.  Lu et al. 2024. Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts. MathVista is another important multimodal benchmark focusing on mathematical reasoning with visual context, used to assess X-REASONER's performance. (No URL provided in the paper's reference list for this specific entry)
8.  Jin et al. 2021. What disease does this patient have? a large-scale open domain question answering dataset from medical exams. The MedQA dataset is crucial for the paper's experiments on cross-domain generalization to medicine and for training the specialized X-REASONER-MED variant. (No URL provided in the paper's reference list for this specific entry)
9.  Muennighoff et al. 2025. S1: Simple test-time scaling. This paper's forced-exiting mechanism is adopted by X-REASONER to mitigate the "endless thinking" issue observed during long-CoT SFT, improving model reliability. URL: http://arxiv.org/abs/2501.19393
10. Zelikman et al. 2022. STaR: Bootstrapping Reasoning With Reasoning. This work, which involves distilling reasoning traces via rejection sampling, is cited as an inspiration for the method used to create the long-CoT data for X-REASONER's SFT stage. URL: http://arxiv.org/abs/2203.14465
